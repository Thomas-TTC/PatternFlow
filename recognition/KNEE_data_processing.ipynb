{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "KNEE_data_processing.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BxQ68rxIBoS"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "import skimage.io\n",
        "import skimage.transform\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "from keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from pathlib import Path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E4mGm-TIBoY"
      },
      "source": [
        "#Directory names of the folders that contain the images that need to be trained and tested for.\n",
        "dir = 'AKOA_Analysis'\n",
        "\n",
        "#The list of class names for which label binarizer is run\n",
        "class_names = ['right', 'left']\n",
        "\n",
        "#channels = 3 ==> RGB or HSV images, channels = 1 ==> Greyscale images\n",
        "channels = 1\n",
        "\n",
        "#Normalization value should be 255 for RGB or Greyscale images. It should be 1 for HSV images.\n",
        "normalizationVal = 255.0\n",
        "\n",
        "#Pretrained Model Filename\n",
        "modelFileName = 'Models//NewIV3-150x150x1-3C.h5'\n",
        "\n",
        "#The filename in which the output weights would be stored.\n",
        "outputWeightsFileName = 'NewIV3-150x150x1-3C-Run1.hdf5'\n",
        "\n",
        "#Other parameters\n",
        "epochs = 100\n",
        "batchsize = 32\n",
        "learningRate = 0.001\n",
        "monitorVariable = 'val_binary_accuracy'\n",
        "monitorMode = 'max'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v_HMd7pIBoc",
        "outputId": "7d201c98-fabb-4b66-93b0-78d7c7e05ea0"
      },
      "source": [
        "#Converting the images to numpy arrays\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "right_count = 0\n",
        "left_count = 0\n",
        "right_end = False\n",
        "left_end = False\n",
        "count = 0\n",
        "\n",
        "for dirname in os.listdir(dir):\n",
        "    if right_end == True and left_end == True:\n",
        "        break\n",
        "    elif 'right' in dirname or 'Right' in dirname or 'R_I_G_H_T' in dirname or 'RIGHT' in dirname:\n",
        "        right_count += 1\n",
        "        PATH = dir + '/' + dirname\n",
        "        image_data = skimage.io.imread(PATH)\n",
        "        new_image_data = skimage.transform.resize(image_data,(150,150,channels))\n",
        "        new_image_data = new_image_data.reshape((1, 150, 150, channels)).astype(np.float32) / normalizationVal\n",
        "        if right_count > 1000:\n",
        "            right_end = True\n",
        "        elif right_count > 800:\n",
        "            X_test.append(new_image_data)\n",
        "            y_test.append(class_names[0])\n",
        "        else:\n",
        "            X_train.append(new_image_data)\n",
        "            y_train.append(class_names[0])\n",
        "    elif 'Left' in dirname or 'L_E_F_T' in dirname or 'LEFT' in dirname:\n",
        "        left_count += 1\n",
        "        PATH = dir + '/' + dirname\n",
        "        image_data = skimage.io.imread(PATH)\n",
        "        new_image_data = skimage.transform.resize(image_data,(150,150,channels))\n",
        "        new_image_data = new_image_data.reshape((1, 150, 150, channels)).astype(np.float32) / normalizationVal\n",
        "        if left_count > 1000:\n",
        "            left_end = True\n",
        "        elif left_count > 800:\n",
        "            X_test.append(new_image_data)\n",
        "            y_test.append(class_names[1])\n",
        "        else:\n",
        "            X_train.append(new_image_data)\n",
        "            y_train.append(class_names[1])\n",
        "print(right_count)\n",
        "print(left_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2240\n",
            "1001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiexN34VIBog",
        "outputId": "b38cd984-eb77-48d5-9a98-da0d96e06ce2"
      },
      "source": [
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "print(len(y_train))\n",
        "print(len(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1600\n",
            "400\n",
            "1600\n",
            "400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4UOPgiVIBok",
        "outputId": "e1b3b084-987b-4b3b-e105-d19f4c4994b0"
      },
      "source": [
        "print(np.size(X_train))\n",
        "print(np.size(y_train)) #The total number of train images per class\n",
        "print(np.size(X_test))\n",
        "print(np.size(y_test))  #The total number of test images per class"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36000000\n",
            "1600\n",
            "9000000\n",
            "400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F27SWHDgIBop"
      },
      "source": [
        "X_train = np.reshape(X_train,(np.size(y_train),150,150,channels))\n",
        "y_train = np.reshape(y_train,(np.size(y_train),1))\n",
        "X_test = np.reshape(X_test,(np.size(y_test),150,150,channels))\n",
        "y_test = np.reshape(y_test,(np.size(y_test),1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xWseP08IBot"
      },
      "source": [
        "#Importing all the necessary libraries from Keras\n",
        "from keras import backend as K\n",
        "from keras import layers\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.models import load_model\n",
        "\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Input\n",
        "from keras.layers import Activation\n",
        "from keras.layers import LeakyReLU\n",
        "\n",
        "#Used for saving the model\n",
        "import h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vzmu2VxIBo4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xnC0CvbIBo8"
      },
      "source": [
        "# im = imresize(im, (h, int(w * aspect_ratio)), interp='bicubic')\n",
        "im = np.array(Image.fromarray(im).resize((h, int(w * aspect_ratio))))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}